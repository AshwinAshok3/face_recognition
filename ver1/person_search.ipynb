{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a48cb234-6cf6-41f7-a616-3844e4f7af60",
   "metadata": {},
   "source": [
    "# CELL 1 — Imports & Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0fb628c-a695-49d2-98e7-397386031384",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"/home/ubuntu_usr/miniconda3/envs/person_ident/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/home/ubuntu_usr/miniconda3/envs/person_ident/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/home/ubuntu_usr/miniconda3/envs/person_ident/lib/python3.9/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/home/ubuntu_usr/miniconda3/envs/person_ident/lib/python3.9/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/home/ubuntu_usr/miniconda3/envs/person_ident/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/home/ubuntu_usr/miniconda3/envs/person_ident/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/home/ubuntu_usr/miniconda3/envs/person_ident/lib/python3.9/asyncio/base_events.py\", line 601, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/home/ubuntu_usr/miniconda3/envs/person_ident/lib/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n",
      "    handle._run()\n",
      "  File \"/home/ubuntu_usr/miniconda3/envs/person_ident/lib/python3.9/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/home/ubuntu_usr/miniconda3/envs/person_ident/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 519, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/home/ubuntu_usr/miniconda3/envs/person_ident/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 508, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/home/ubuntu_usr/miniconda3/envs/person_ident/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 400, in dispatch_shell\n",
      "    await result\n",
      "  File \"/home/ubuntu_usr/miniconda3/envs/person_ident/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 368, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/home/ubuntu_usr/miniconda3/envs/person_ident/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 767, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/home/ubuntu_usr/miniconda3/envs/person_ident/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 455, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/home/ubuntu_usr/miniconda3/envs/person_ident/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 602, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/home/ubuntu_usr/miniconda3/envs/person_ident/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3048, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/home/ubuntu_usr/miniconda3/envs/person_ident/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3103, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/home/ubuntu_usr/miniconda3/envs/person_ident/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/home/ubuntu_usr/miniconda3/envs/person_ident/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3308, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/home/ubuntu_usr/miniconda3/envs/person_ident/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3490, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/home/ubuntu_usr/miniconda3/envs/person_ident/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3550, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_12170/164977420.py\", line 5, in <module>\n",
      "    from insightface.app import FaceAnalysis\n",
      "  File \"/home/ubuntu_usr/miniconda3/envs/person_ident/lib/python3.9/site-packages/insightface/__init__.py\", line 8, in <module>\n",
      "    import onnxruntime\n",
      "  File \"/home/ubuntu_usr/miniconda3/envs/person_ident/lib/python3.9/site-packages/onnxruntime/__init__.py\", line 23, in <module>\n",
      "    from onnxruntime.capi._pybind_state import ExecutionMode  # noqa: F401\n",
      "  File \"/home/ubuntu_usr/miniconda3/envs/person_ident/lib/python3.9/site-packages/onnxruntime/capi/_pybind_state.py\", line 32, in <module>\n",
      "    from .onnxruntime_pybind11_state import *  # noqa\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "_ARRAY_API not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: _ARRAY_API not found"
     ]
    },
    {
     "ename": "SystemError",
     "evalue": "<built-in function __import__> returned a result with an error set",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;31mImportError\u001b[0m: numpy.core.multiarray failed to import",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mSystemError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;31mSystemError\u001b[0m: <built-in function __import__> returned a result with an error set"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu_usr/miniconda3/envs/person_ident/lib/python3.9/site-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 2.0.8 (you have 1.4.24). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "from insightface.app import FaceAnalysis\n",
    "from scipy.spatial.distance import cosine\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c2772ac-24c2-4aa0-9e02-a3ae504c83d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "SIM_THRESHOLD = 0.50   # 50% as you requested\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1735b5b6-7381-4b29-8773-84e1ed55e093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21fb05be-b12f-44c4-9a50-fdc0324d5227",
   "metadata": {},
   "source": [
    "# CELL 2 — Load Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98534200-7853-4036-8592-c93592f0a1cf",
   "metadata": {},
   "source": [
    "#### Yolo v8 - Person Detection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9dab010c-2afc-4cef-944d-131a57ee9d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo = YOLO(\"yolov8n.pt\")  # use yolov8s.pt if GPU is good\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b25610-abba-410c-a11d-dde2f2b26c3a",
   "metadata": {},
   "source": [
    "#### InsightFace (Face Recognition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a312ae7b-3cdc-4706-929c-8efec0947923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: /home/ubuntu_usr/.insightface/models/buffalo_l/1k3d68.onnx landmark_3d_68 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: /home/ubuntu_usr/.insightface/models/buffalo_l/2d106det.onnx landmark_2d_106 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: /home/ubuntu_usr/.insightface/models/buffalo_l/det_10g.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: /home/ubuntu_usr/.insightface/models/buffalo_l/genderage.onnx genderage ['None', 3, 96, 96] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: /home/ubuntu_usr/.insightface/models/buffalo_l/w600k_r50.onnx recognition ['None', 3, 112, 112] 127.5 127.5\n",
      "set det-size: (640, 640)\n"
     ]
    }
   ],
   "source": [
    "face_app = FaceAnalysis(\n",
    "    name=\"buffalo_l\",\n",
    "    providers=[\"CPUExecutionProvider\"]\n",
    ")\n",
    "\n",
    "# CRITICAL: ctx_id = -1 for CPU\n",
    "face_app.prepare(ctx_id=-1, det_size=(640, 640))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30854390-da9e-4b81-9ebc-6d49e8660782",
   "metadata": {},
   "source": [
    "# CELL 3 — Reference Image Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6e160b7-5a18-45d4-8d1b-4e3b33ef3fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reference_embedding(img_path):\n",
    "    img = cv2.imread(img_path)\n",
    "\n",
    "    if img is None:\n",
    "        raise ValueError(f\"Image not found or unreadable: {img_path}\")\n",
    "\n",
    "    faces = face_app.get(img)\n",
    "\n",
    "    if not faces:\n",
    "        raise ValueError(\"No face found in reference image\")\n",
    "\n",
    "    # largest face by area\n",
    "    faces = sorted(\n",
    "        faces,\n",
    "        key=lambda f: (f.bbox[2] - f.bbox[0]) * (f.bbox[3] - f.bbox[1]),\n",
    "        reverse=True\n",
    "    )\n",
    "\n",
    "    return faces[0].embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "087a1ffd-37b9-444b-b876-fa3ea602b97d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TensorrtExecutionProvider', 'CUDAExecutionProvider', 'AzureExecutionProvider', 'CPUExecutionProvider']\n"
     ]
    }
   ],
   "source": [
    "import onnxruntime as ort\n",
    "print(ort.get_available_providers())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e6497d2-6e16-41f5-a836-6e0477dc0862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/f/keltron/projects/person_detection\n"
     ]
    }
   ],
   "source": [
    "abs_path = os.getcwd()\n",
    "print(abs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca9764eb-0e67-417c-8dd8-2aabf31a6ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/f/keltron/projects/person_detection/data_check/chris_patt_img_test.jpg\n"
     ]
    }
   ],
   "source": [
    "img_path = abs_path + \"/\" + \"data_check/chris_patt_img_test.jpg\"\n",
    "print(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f75437-d1a5-4abd-8486-73f245da7000",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_embedding = get_reference_embedding(img_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992b9b32-dc68-4888-9648-62c19f6c059f",
   "metadata": {},
   "source": [
    "# CELL 4 — Video / Webcam Processing\n",
    "\n",
    "Supports:\n",
    "\n",
    "* Webcam\n",
    "* USB camera\n",
    "* Video file\n",
    "* 4K HDR (OpenCV handles it, FPS will drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae49c5e-7203-4101-b5a8-7f88b74eeeea",
   "metadata": {},
   "outputs": [],
   "source": [
    "vid_path = abs_path + \"/\" + \"data_check/video_of_christ_patt.mp4\"\n",
    "print(vid_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b84342a-ee72-473b-ae1e-305d913760da",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(vid_path)  # changed to video path if needed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bafa65fa-9a45-451e-9d8d-ea6c122fa17d",
   "metadata": {},
   "source": [
    "# CELL 5 — Core Matching + Visualization Logic\n",
    "\n",
    "This is where everything comes together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5460ccb8-8f33-4881-a978-ca3c77153fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_color():\n",
    "    return tuple(random.randint(0,255) for _ in range(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf355d28-1ad0-4cd7-8862-e926a2ca709d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- setup video writer once ---\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "out = cv2.VideoWriter(\n",
    "    \"person_search_output.mp4\",\n",
    "    fourcc,\n",
    "    fps if fps > 0 else 25,\n",
    "    (width, height)\n",
    ")\n",
    "\n",
    "frame_id = 0\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    detections = yolo(frame, conf=0.4, classes=[0])[0]  # person class\n",
    "\n",
    "    found = False\n",
    "    best_match = 0.0\n",
    "\n",
    "    for box in detections.boxes:\n",
    "        x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "\n",
    "        # safety clamp (avoid empty crops)\n",
    "        x1, y1 = max(0, x1), max(0, y1)\n",
    "        x2, y2 = min(frame.shape[1], x2), min(frame.shape[0], y2)\n",
    "\n",
    "        person_crop = frame[y1:y2, x1:x2]\n",
    "        if person_crop.size == 0:\n",
    "            continue\n",
    "\n",
    "        faces = face_app.get(person_crop)\n",
    "        if not faces:\n",
    "            continue\n",
    "\n",
    "        face = faces[0]\n",
    "        emb = face.embedding\n",
    "        similarity = 1 - cosine(ref_embedding, emb)\n",
    "        similarity_pct = similarity * 100\n",
    "\n",
    "        best_match = max(best_match, similarity_pct)\n",
    "\n",
    "        if similarity_pct > SIM_THRESHOLD * 100:\n",
    "            found = True\n",
    "            label = f\"TARGET FOUND: {similarity_pct:.1f}%\"\n",
    "            color = (0, 255, 0)\n",
    "            thickness = 3\n",
    "        else:\n",
    "            label = f\"Resemblance: {similarity_pct:.1f}%\"\n",
    "            color = random_color()\n",
    "            thickness = 2\n",
    "\n",
    "        cv2.rectangle(frame, (x1, y1), (x2, y2), color, thickness)\n",
    "        cv2.putText(\n",
    "            frame,\n",
    "            label,\n",
    "            (x1, max(0, y1 - 10)),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            0.6,\n",
    "            color,\n",
    "            2\n",
    "        )\n",
    "\n",
    "    if not found and best_match < 50:\n",
    "        cv2.putText(\n",
    "            frame,\n",
    "            \"TARGET NOT FOUND\",\n",
    "            (20, 40),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            1.0,\n",
    "            (0, 0, 255),\n",
    "            3\n",
    "        )\n",
    "\n",
    "    # write annotated frame to file\n",
    "    out.write(frame)\n",
    "\n",
    "    frame_id += 1\n",
    "    if frame_id % 100 == 0:\n",
    "        print(f\"[INFO] processed {frame_id} frames\")\n",
    "\n",
    "cap.release()\n",
    "out.release()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
